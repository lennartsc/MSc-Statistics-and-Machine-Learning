{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2: Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text classification is the task of sorting text documents into predefined classes. The concrete problem you will be working on in this lab is the classification of texts with respect to their political affiliation. The specific texts you are going to classify are speeches held in the [Riksdag](https://www.riksdagen.se/en/), the Swedish national legislature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data for this lab comes from [The Riksdag’s Open Data](https://data.riksdagen.se/in-english/). We have tokenized the speeches and put them into two compressed [JSON](https://en.wikipedia.org/wiki/JSON) files:\n",
    "\n",
    "* `speeches-201718.json.bz2` (speeches from the 2017/2018 parliamentary session)\n",
    "* `speeches-201819.json.bz2` (ditto, from the 2018/2019 session)\n",
    "\n",
    "We start by loading these files into two separate data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "\n",
    "with bz2.open(\"speeches-201718.json.bz2\") as source:\n",
    "    speeches_201718 = pd.read_json(source)\n",
    "\n",
    "with bz2.open(\"speeches-201819.json.bz2\") as source:\n",
    "    speeches_201819 = pd.read_json(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you inspect the two data frames, you can see that there are three labelled columns: `id` (the official speech ID), `words` (the space-separated words of the speech), and `party` (the party of the speaker, represented by its customary abbreviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>party</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H5-002-004</td>\n",
       "      <td>S</td>\n",
       "      <td>eders majestäter eders kungliga högheter herr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H5-003-001</td>\n",
       "      <td>V</td>\n",
       "      <td>aktuell debatt om situationen för ensamkommand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H5-003-002</td>\n",
       "      <td>S</td>\n",
       "      <td>herr talman och ledamöter jag vill börja med a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H5-003-003</td>\n",
       "      <td>M</td>\n",
       "      <td>herr talman åhörare den här debatten handlar a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H5-003-004</td>\n",
       "      <td>SD</td>\n",
       "      <td>herr talman ansvar och rättssäkerhet är två or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id party                                              words\n",
       "0  H5-002-004     S  eders majestäter eders kungliga högheter herr ...\n",
       "1  H5-003-001     V  aktuell debatt om situationen för ensamkommand...\n",
       "2  H5-003-002     S  herr talman och ledamöter jag vill börja med a...\n",
       "3  H5-003-003     M  herr talman åhörare den här debatten handlar a...\n",
       "4  H5-003-004    SD  herr talman ansvar och rättssäkerhet är två or..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_201718.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the lab, we will be using the speeches from 2017/2018 as our training data, and the speeches from 2018/2019 as our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = speeches_201718, speeches_201819"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later reference, we store the sorted list of party abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'KD', 'L', 'M', 'MP', 'S', 'SD', 'V']\n"
     ]
    }
   ],
   "source": [
    "parties = sorted(training_data[\"party\"].unique())\n",
    "print(parties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to get to know the data better by plotting a simple visualization.\n",
    "\n",
    "If you are not familiar with the Swedish political system and the parties represented in the Riksdag in particular, then we suggest that you have a look at the Wikipedia article about the [2018 Swedish general election](https://en.wikipedia.org/wiki/2018_Swedish_general_election).\n",
    "\n",
    "For the lab, we ask you to compare the two data frames with respect to the distribution of the speeches over the different parties. Write code to generate two bar plots that visualize this information, one for the 2017/2018 speeches and one for the 2018/2019 speeches. Inspect the two plots, and compare them\n",
    "\n",
    "* to each other\n",
    "* to the results of the 2014 and the 2018 general elections\n",
    "\n",
    "Summarize your observations in a short text in the cell below.\n",
    "\n",
    "**Tip:** If you need help with creating bar plots, [Bar Plot using Pandas](https://dfrieds.com/data-visualizations/bar-plot-python-pandas) provides a useful tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting training data.\n",
    "plt.bar(x = training_data['party'].value_counts().index, \n",
    "        height = speeches_201718['party'].value_counts(),\n",
    "        color = ['black', 'red', 'green', 'blue', 'cyan', 'yellow', 'orange', 'grey'])\n",
    "plt.title('Training data')\n",
    "plt.xlabel('Party')\n",
    "plt.ylabel('# speeches')\n",
    "plt.show()\n",
    "\n",
    "# PLotting test data.\n",
    "plt.bar(x = test_data['party'].value_counts().index, \n",
    "        height = speeches_201718['party'].value_counts(),\n",
    "        color = ['black', 'red', 'green', 'blue', 'cyan', 'yellow', 'orange', 'grey'])\n",
    "plt.title('Test data')\n",
    "plt.xlabel('Party')\n",
    "plt.ylabel('# speeches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2014</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>31.01</td>\n",
       "      <td>28.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>23.33</td>\n",
       "      <td>19.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>12.86</td>\n",
       "      <td>17.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MP</th>\n",
       "      <td>6.89</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>6.11</td>\n",
       "      <td>8.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>5.72</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP/L</th>\n",
       "      <td>5.42</td>\n",
       "      <td>5.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KD</th>\n",
       "      <td>4.57</td>\n",
       "      <td>6.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       2014   2018\n",
       "S     31.01  28.26\n",
       "M     23.33  19.84\n",
       "SD    12.86  17.53\n",
       "MP     6.89   4.41\n",
       "C      6.11   8.61\n",
       "V      5.72   8.00\n",
       "FP/L   5.42   5.49\n",
       "KD     4.57   6.32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing election results from 2014 and 2018.\n",
    "pd.DataFrame({\"2014\" : [31.01, 23.33, 12.86, 6.89, 6.11, 5.72, 5.42, 4.57],\n",
    "              \"2018\" : [28.26, 19.84, 17.53, 4.41, 8.61, 8.00, 5.49, 6.32]},\n",
    "             index = [\"S\", \"M\", \"SD\", \"MP\", \"C\", \"V\", \"FP/L\", \"KD\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, in 2017/2018 the total number of speeches was higher. Parties S and M in both years gave the 1st and 2nd most number of speeches. Party L is always the party with the least speeches.\n",
    "From the 2014 election results we can see that the largest two parties S and M are also the parties that held the most speeches, same goes for the 2018 election."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to train and evaluate a classifier. More specifically, we ask you to train a [Multinomial Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes) classifier. You will have to\n",
    "\n",
    "1. vectorize the speeches in the training data\n",
    "2. instantiate and fit the Naive Bayes model\n",
    "3. evaluate the model on the test data\n",
    "\n",
    "The scikit-learn library provides a convenience class [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) that allows you to solve the first two tasks with very compact code. For the evaluation you can use the function [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html), which will report per-class precision, recall and F1, as well as overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.63      0.04      0.07       671\n",
      "          KD       0.70      0.02      0.03       821\n",
      "           L       0.92      0.02      0.04       560\n",
      "           M       0.36      0.68      0.47      1644\n",
      "          MP       0.36      0.25      0.29       809\n",
      "           S       0.46      0.84      0.59      2773\n",
      "          SD       0.57      0.12      0.20      1060\n",
      "           V       0.59      0.15      0.24       950\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      9288\n",
      "   macro avg       0.57      0.26      0.24      9288\n",
      "weighted avg       0.52      0.43      0.34      9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate pipeline.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nb_pipeline = make_pipeline(CountVectorizer(), # Vectorizing speeches in training data. \n",
    "                            MultinomialNB()) # Training Multinomial Naive Bayes classifier.\n",
    "\n",
    "# Using pipeline to train naive bayes classifier on training data.\n",
    "nb_classifier = nb_pipeline.fit(training_data[\"words\"], training_data[\"party\"])  \n",
    "\n",
    "# Evaluating model on test data.\n",
    "test_predictions = nb_classifier.predict(test_data[\"words\"])\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_data[\"party\"], test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you have expected the results that you got?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would have expected to get a similar result. The overall classififer's accuracy is 43%. Since there are eight different class values, it is not easy to always predict the correct class. The Naive Bayes classifier assumes the features to be independet of each other which is a naive assumption. To assess the accuracy, we need to compare it to the accuracy of other classifiers, thouhgh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation metrics such as accuracy should not be understood as absolute measures of performance, but should be used only to compare different classifiers. When other classifiers are not available, a simple baseline for text classification is **Most Frequent Class (MFC)**. One way to think of this baseline is as a classifier that, for every document, predicts that class which appears most often in the training data.\n",
    "\n",
    "Determine the most frequent class in the 2017/2018 data. What is the accuracy of the MFC baseline on the test data? Given this baseline accuracy, how do you assess the results of the Naive Bayes classifier from Problem&nbsp;2? Answer with a short text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S     4261\n",
      "M     2370\n",
      "MP    1481\n",
      "SD    1010\n",
      "V      894\n",
      "C      865\n",
      "KD     743\n",
      "L      719\n",
      "Name: party, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.00      0.00      0.00       671\n",
      "          KD       0.00      0.00      0.00       821\n",
      "           L       0.00      0.00      0.00       560\n",
      "           M       0.00      0.00      0.00      1644\n",
      "          MP       0.00      0.00      0.00       809\n",
      "           S       0.30      1.00      0.46      2773\n",
      "          SD       0.00      0.00      0.00      1060\n",
      "           V       0.00      0.00      0.00       950\n",
      "\n",
      "   micro avg       0.30      0.30      0.30      9288\n",
      "   macro avg       0.04      0.12      0.06      9288\n",
      "weighted avg       0.09      0.30      0.14      9288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lennart\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Identifying most frequent class within training data.\n",
    "print(training_data[\"party\"].value_counts())\n",
    "'''It follows that the most frequent class within the training data is class \"S\", as it also could be seen already in the \n",
    "plot above.'''\n",
    "\n",
    "# Computing accuracy of predictions for test data using always most Frequent Class as the prediction.\n",
    "import numpy as np\n",
    "print(classification_report(test_data[\"party\"], np.repeat(\"S\", len(test_data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained overall accurary is 30%, so it's much lower than the accuracy of the Naive Bayes classifier. However, the classififer of course only predits the class \"S\" to every input. Thus, for all speeches to be classified that are not from the party \"S\", the accuracy is 0%. As a consequence, the Naive Bayes classifier performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Creating a balanced data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you saw in Problem&nbsp;1, the distribution of the speeches over the eight different parties (classes) is imbalanced. One technique used to alleviate this is **undersampling**, in which one randomly removes samples from over-represented classes until all classes are represented with the same number of samples.\n",
    "\n",
    "Implement undersampling to create a balanced subset of the training data. Rerun the evaluation from Problem&nbsp;2 on the balanced data and compare the results. Discuss your findings in a short text. Would you argue that undersampling make sense for the task of predicting the party of a speaker?\n",
    "\n",
    "**Hint:** Your balanced subset should consist of 5,752 speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speeches for balanced data: 5752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.26      0.45      0.33       671\n",
      "          KD       0.29      0.38      0.33       821\n",
      "           L       0.28      0.43      0.34       560\n",
      "           M       0.41      0.48      0.44      1644\n",
      "          MP       0.34      0.40      0.37       809\n",
      "           S       0.80      0.28      0.41      2773\n",
      "          SD       0.45      0.40      0.42      1060\n",
      "           V       0.37      0.56      0.45       950\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      9288\n",
      "   macro avg       0.40      0.42      0.39      9288\n",
      "weighted avg       0.49      0.40      0.40      9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performing undersampling.\n",
    "## Identifying number of samples for each party so that training data would be balanced over parties. \n",
    "n_samples_desired = training_data['party'].value_counts().min()\n",
    "## Initializing empty data frame.\n",
    "training_data_balanced = pd.DataFrame()\n",
    "## Sampling training data for each party and append sampled data to initialized data frame.\n",
    "for party in training_data['party'].unique():\n",
    "    # Subsetting part of training data referring to the party.\n",
    "    train_party = training_data[training_data.party == party]\n",
    "    # Sampling n_samples_desired times from subset without replacement.\n",
    "    train_party = train_party.sample(n = n_samples_desired, replace = False)\n",
    "    # Appending sampled training data of specific party to initialized data frame.\n",
    "    training_data_balanced = training_data_balanced.append(train_party)\n",
    "## Checking number of rows of balanced training data.\n",
    "print(\"Number of speeches for balanced data: \" + str(len(training_data_balanced)))\n",
    "\n",
    "# Redoing process from Problem 2 on balanced data.\n",
    "## Using pipeline from Problem 2 to train naive bayes classifier on balanced data.\n",
    "nb_classifier = nb_pipeline.fit(training_data_balanced[\"words\"], training_data_balanced[\"party\"])  \n",
    "# Evaluating model on test data.\n",
    "test_predictions = nb_classifier.predict(test_data[\"words\"])\n",
    "print(classification_report(test_data[\"party\"], test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy (now 40%) decreased compared to the accuracy in Problem 2. Thus, the new classifier which has been built on the balanced training dataset performs worse compared to before. The reason might be that the amount of training data has been decreased a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **confusion matrix** is a specific table layout that is useful when analysing the performance of a classifier. In this matrix, both the rows and the columns correspond to classes, and each cell $(i, j)$ states how many times a sample with gold-standard class $i$ was predicted as belonging to class $j$.\n",
    "\n",
    "In scitkit-learn, the confusion matrix of a classifier is computed by the function [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html).\n",
    "\n",
    "Your task is to use the confusion matrix to find, for each given party $p$ in the Riksdag, that other party $p'$ which the classifier that you trained in Problem&nbsp;4 most often confuses $p$ with when it predicts the party of a speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      C   KD    L    M   MP    S   SD    V\n",
      "C   303   69   42   97   47   13   44   56\n",
      "KD   95  312   58  165   31   25   56   79\n",
      "L    59   48  240   70   23   16   35   69\n",
      "M   229  176  127  787   73   33  105  114\n",
      "MP   64   55   58   98  321   73   43   97\n",
      "S   248  228  168  460  349  772  177  371\n",
      "SD  106  103  108  144   40   17  426  116\n",
      "V    59   71   59  109   47   12   59  534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true = test_data[\"party\"], \n",
    "                                                    y_pred = test_predictions),\n",
    "                                   index = parties, \n",
    "                                   columns = parties)\n",
    "print(confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use index and columns according to the sorted parties, because we did not specify labels within confusion_matrix().\n",
    "Within the description of the label parameter for the function confusion_matri(), it says the following: \n",
    "\"If none is given, those that appear at least once  in y_true or y_pred are used in sorted order.\n",
    "\n",
    "The left lables refer to the true values, the labels on top refer to the predictions.\n",
    "\n",
    "Our goal is to find for each party the other party that most have been predicted instead of the true party by our classifer.\n",
    "Thus, for each party, we need to find the other party with the maximum number of predictions which is not the party itself.\n",
    "We achieve this by finding the maximum value for each row which does not correspond the true party itself.\n",
    "First, we set the diagonal of the confusion matrix to zero so that the true class is considered in our analysis.\n",
    "Afterwards, rowwise, we are looking for the maximum value. The corresponding column name then is the party we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C     M\n",
       "KD    M\n",
       "L     M\n",
       "M     C\n",
       "MP    M\n",
       "S     M\n",
       "SD    M\n",
       "V     M\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting diagonal of confusion matrix to zero.\n",
    "for i in range(len(confusion_matrix_df)):\n",
    "    confusion_matrix_df.iloc[i, i] = 0\n",
    "\n",
    "# Row-wise identfying label of maximum value.\n",
    "confusion_matrix_df.idxmax(axis = \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, you have been using the vectorizer and the Naive Bayes classifier with their default hyperparameters. When working with real-world applications, you would want to find settings for the hyperparameters that maximize the performance for the task at hand.\n",
    "\n",
    "Manually tweaking the hyperparameters of the various components of a vectorizer–classifier pipeline can be cumbersome. However, scikit-learn makes it possible to run an exhaustive search for the best hyperparameters over a grid of possible values. This method is known as **grid search**.\n",
    "\n",
    "The hyperparameters of a pipeline should never be tuned on the final test set. (Why would that be a bad idea?) Instead, one should either use a separate validation set, or run cross-validation over different folds. Here we will use cross-validation.\n",
    "\n",
    "Implement a grid search with 5-fold cross-validation to find the optimal parameters in a grid defined by the following choices for the hyperparameters:\n",
    "\n",
    "* In the vectorizer, try a set-of-words model instead of the default bag-of-words model (two possible parameter values).\n",
    "* Also in the vectorizer, try extracting $n$-grams up to $n = 2$ (two possible parameter values).\n",
    "* In the Naive Bayes classifier, try using additive smoothing with $\\alpha \\in \\{1, 0{.}1\\}$ (two possible parameter values).\n",
    "\n",
    "Use the class [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) from the scikit-learn library. Print the results of your best model, along with the parameter values that yielded these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid={'vect__binary': (True, False)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefining pipeline by including names for each pipeline-step.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "nb_pipeline = Pipeline([('vect', CountVectorizer()), # Vectorizing speeches in training data. \n",
    "                        ('clf', MultinomialNB())]) # Training Multinomial Naive Bayes classifier.\n",
    "\n",
    "# Defining parameters to loop over. Names connected to name of pipeline-step.\n",
    "parameters = {'vect__binary': (True, False)}#, # refers to binary-parameter of CountVectorizer().\n",
    "              #'vect__ngram_range': [(1, 1), (1, 2)], # refers to ngram-parameter of CountVectorizer().\n",
    "              #'clf__alpha': (1, 0.1)} # refers to alpha-parameter of MultinomialNB().\n",
    "\n",
    "# Creating GridSearch-instance.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs_nb_classifier = GridSearchCV(nb_pipeline, # Defined pipeline.\n",
    "                                parameters, # Specified parameters.\n",
    "                                cv = 5, # Number of folds.\n",
    "                                iid = False, \n",
    "                                n_jobs = -1) # Grid search will detect how many cores are installed and use them all.\n",
    "\n",
    "# Training classifier for each parameter setting.\n",
    "gs_nb_classifier = gs_nb_classifier.fit(training_data[\"words\"], training_data[\"party\"])\n",
    "\n",
    "# Evaluating model on training data.\n",
    "gs_nb_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5065151150080454"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_nb_classifier.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_nb_classifier.best_params_\n",
    "train_pred = gs_nb_classifier.predict(training_data[\"words\"])\n",
    "test_pred = gs_nb_classifier.predict(test_data[\"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.98      0.45      0.62       865\n",
      "          KD       0.98      0.33      0.49       743\n",
      "           L       1.00      0.36      0.53       719\n",
      "           M       0.62      0.95      0.75      2370\n",
      "          MP       0.89      0.64      0.74      1481\n",
      "           S       0.74      0.96      0.84      4261\n",
      "          SD       0.96      0.59      0.73      1010\n",
      "           V       0.95      0.66      0.78       894\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     12343\n",
      "   macro avg       0.89      0.62      0.69     12343\n",
      "weighted avg       0.82      0.76      0.74     12343\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.63      0.04      0.07       671\n",
      "          KD       0.70      0.02      0.03       821\n",
      "           L       0.92      0.02      0.04       560\n",
      "           M       0.36      0.68      0.47      1644\n",
      "          MP       0.36      0.25      0.29       809\n",
      "           S       0.46      0.84      0.59      2773\n",
      "          SD       0.57      0.12      0.20      1060\n",
      "           V       0.59      0.15      0.24       950\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      9288\n",
      "   macro avg       0.57      0.26      0.24      9288\n",
      "weighted avg       0.52      0.43      0.34      9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(training_data[\"party\"], train_pred))\n",
    "print(classification_report(test_data[\"party\"], test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Try to improve your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn makes it easy to test different vectorizer–classifier pipelines – among other things, it includes different types of logistic regression classifiers, support vector machines, and decision trees. Browse the library to see which methods are supported.\n",
    "\n",
    "Build a pipeline that you find interesting, and use grid search to find optimal settings for the hyperparameters. Print the results of your best model. Did you manage to get better results than the ones that you obtained in Problem&nbsp;5? Answer with a short text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__criterion': 'gini'}\n",
      "0.42185426473048004\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Redefining pipeline by including names for each pipeline-step.\n",
    "dt_pipeline = Pipeline([('vect', CountVectorizer()), # Vectorizing speeches in training data. \n",
    "                        ('clf', tree.DecisionTreeClassifier())]) # Training decision tree classifier.\n",
    "\n",
    "# Defining parameters to loop over. Names connected to name of pipeline-step.\n",
    "parameters = {'clf__criterion': ('gini','entropy')} # refers to criterion-parameter of DecisionTreeClassifier()().\n",
    "\n",
    "# Creating GridSearch-instance.\n",
    "gs_dt_classifier = GridSearchCV(dt_pipeline, # Defined pipeline.\n",
    "                                parameters, # Specified parameters.\n",
    "                                cv = 5, # Number of folds .\n",
    "                                iid = False, \n",
    "                                n_jobs = -1) # Grid search will detect how many cores are installed and use them all.\n",
    "\n",
    "# Training classifier for each parameter setting.\n",
    "gs_dt_classifier = gs_dt_classifier.fit(training_data[\"words\"], training_data[\"party\"])\n",
    "\n",
    "# Evaluating model on training data.\n",
    "print(gs_dt_classifier.best_params_)\n",
    "print(gs_dt_classifier.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, the best accuracy obtained is only around 42% which is less than the accuracy obtained by the Naive Bayes classifier from before. Thus, this decision tree classifier did not manage to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Please read the section ‘General information’ on the ‘Labs’ page of the course website before submitting this notebook!\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
